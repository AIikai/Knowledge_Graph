### 知识融合

知识融合是面向知识服务和决策问题，以多源异构数据为基础，在本体库和规则库的支持下，通过知识抽取和转换获得隐藏在数据资源中的知识因子及其关联关系，进而在语义层次上组合、推理、创造出新知识的过程，并且这个过程需要根据数据源的变化和用户反馈进行实时动态调整。
知识融合从融合层面划分可以分为数据层知识融合和概念层数据融合。前者是指多源数据对齐，后者是指对多个知识库或信息源在概念层进行模式对齐。工具有Falcon-AO、YAM++、Dedupe等。

- 本体对齐

  本体对齐或者本体匹配是概念层知识融合的主要研究任务，是指确定本体概念之间映射关系的过程。

	- 核心

		- 如何通过本体概念之间的相似性度量，发现异构本体间的匹配关系

	- 方法

		- 基于结构、基于实例
		- 基于语言学的匹配、基于文本的匹配、基于已知本体实体联结的匹配

- 实体链接

  实体链接是数据层知识融合的主要任务，主要方法有基于实体知识的链接方法、基于篇章主题的链接方法和融合实体知识与篇章主题的链接方法。
  
  实体链接主要解决实体名的歧义性和多样性问题，是指将文本中实体名指向其所代表的真实世界实体的任务，也通常被称为实体消歧（也有人认为实体链接是实体识别和实体消歧的联合过程）。
  
  Entity Linking，难点在于两个原因，即Mention Variations（多词一义）和Entity Ambiguity（一词多义），多词一义是指同一实体有不同的mention，实体的标准名、别名、名称缩写等都可以用来指代该实体，如宋江，可以用及时雨、孝义黑三郎、宋押司来指代；一词多义是指同一mention对应不同的实体，比如苹果，可能指水果，也可能指的是苹果公司/手机/电脑。
  
  资料：
  https://zhuanlan.zhihu.com/p/100248426
  http://nlpprogress.com/english/entity_linking.html

	- 核心

		- 构建多类型多模态上下文及知识的统一表示，并建模不同信息、不同证据之间的相互交互

	- 方案

		- 1. Candidate Entity Generation(CEG, 候选实体生成)

		  最有效的方法是Name Dictionary，即词典匹配，构建实体映射词表。说白了就是配别名，如首字母缩写、模糊匹配、昵称、常见拼写错误等。
		  
		  构建方法：
		  a. 百科网站（标题、重定向页、消歧页、加粗短语/小别名、超链接）；
		  b. 基于搜索引擎：调Google API，搜mention。若前m个有wiki entity，建立map；
		  c. 直接抽取知识图谱中已有的别名；
		  d. 规则构建；
		  e. 人工标注、用户日志。
		  
		  文本与词典之间的匹配规则可分为完全匹配和模糊匹配。模糊匹配有那么几种情况，输入文本和词典词二者之间是a包含b或者b包含a的关系，则匹配成功；二者之间存在一定程度的重叠，则匹配成功；二者符合字符串相似度算法，character dice score, skip bigram dice score, hamming distance等。

		- 2. Entity Disambiguation (ED, 实体消歧)

		  候选实体排序（概率/相似度）
		  
		  	a. 利用上下文无关特征，如mention到实体的Link Count，实体自身的一些属性（比如热度、类型等）。例如，问“姚明有多高？”时，大概率是在问篮球明星姚明，而不是其他默默无闻的“姚明”。
		  
		  	b. 分类模型：根据有标注的语料，利用上下文等构建特征向量。输入是候选实体的信息和Entity Mention的特征信息、上下文信息。
		  案例|CCKS_2019 entity_link  No.1
		  https://github.com/panchunguang/ccks_baidu_entity_link
		  
		  	c. 空间向量模型：根据上下文分别构建指称实体和候选实体的特征向量，然后计算它们的余弦相似度，选取相似度最高的候选实体作为目标实体。它可以有效利用上下文信息；但空间向量为词袋模型，不能反映词语之间的语义关系，会带来维度灾难与语义隔绝的问题。
		  
		  	d. 排序模型：利用Learn to Rank(LTR)排序模型，根据查询与文档的文本相似度（余弦相似度）、欧氏距离、编辑距离、主题相似度、实体流行度等特征进行训练和预测，选取排序最高的作为目标实体。它的优势就是可以有效地融入不同的特征。
		  案例|LTR
		  https://github.com/ChenglongChen/tensorflow-LTR
		  
		  	e. 主题模型：根据指称实体与候选实体的主题分布相似度进行目标实体的确认。该方法的主要优势是能在一定程度上反映实体的语义相关性，避免维度灾难，在上下文信息比较丰富的情况下，能够取得很好的效果。

		- 3. Unlinkable Mention Prediction (无链接指代预测)

		  由于知识图谱的不完备性，会出现实体提及在知识图谱中无相对应的实体的情况，此时，对应实体应是“空实体（NIL）”。
		  
		  a. NIL Threshold：设置一个置信度阈值，如果Top_1的候选实体的预测得分小于阈值，则判定不在知识库中。
		  
		  b. Binary Classification：训练一个二分类模型，判断Top_ranked Entity是否真的是Mention表达的实体。
		  
		  c. Rank with NIL：rank的时候，候选实体中加入NIL。
