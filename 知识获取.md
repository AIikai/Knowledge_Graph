### 知识获取

知识图谱中的知识来源于结构化、半结构化和非结构化的信息资源。知识获取即通过获取这些不同来源、不同结构的知识，形成结构化的知识并存储到知识图谱中。当前的知识抽取主要针对文本数据进行，需要解决的抽取问题包括：实体抽取、关系抽取、属性抽取和事件抽取。

- 实体抽取：见实体识别.md

- 关系抽取

  利用多种技术自动从文本中发现命名实体之间的语义关系，将文本中的关系映射到实体关系三元组上。研究难点是关系表达的隐含性（关系不一定明显）、关系的复杂性（二元或多元）、语言的多样性（关系有多种表述形式）。

	- 1. 基于模板匹配

	  模板匹配是关系分类中比较常见的方法，使用一个模板库对输入文本中的两个给定实体进行上下文匹配，如果满足模板对应关系，则作为实体对之间的关系。
	  
	  优势：实现与构建简单，适用于小规模特定领域，效果好
	  劣势：召回率低、可移植性差，不适合大规模及通用领域

		- a. 人工模板

		  主要用于判断实体间是否存在上下位关系。上下位关系的自然语言表达方式相对有限，采用人工模板就可以很好地完成关系分类。

		- b. 统计模板

		  无需人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。

	- 2. 基于深度学习有监督方法

		- a. 流水线关系抽取Pipeline

		  Pipeline方法中，关系抽取通常转化为一个分类问题，前提是关系类型数目是确定的，如果关系无法完全列举，则可将关系抽取转化为一个相似度匹配任务（问句与属性/关系的匹配）。
		  
		  案例|NER --> RE (Bert + Dense) 关系分类
		  优势：把关系抽取当作一个简单的分类问题，高质量监督数据下的模型的准确率会很高。
		  劣势：需要大量的人力和时间成本做数据标注，难以拓展新的关系类别，模型较为脆弱，泛化能力有限。
		  https://github.com/yuanxiaosc/Entity-Relation-Extraction
		  
		  a-1 Matching the Blanks: Distributional Similarity for Relation Learning
		    
		  本文基于Bert，采用6种不同结构进行实体对的pooling，然后将pooling进行关系分类或关系相似度计算，结论是(f)效果最好。
		  优势：提出了关系抽取预训练任务Matching the blanks，在少样本关系抽取任务上效果提升明显，适用于少数据的场景。
		  https://arxiv.org/pdf/1906.03158.pdf
		  https://github.com/zhpmatrix/BERTem
		  
		  a-2 Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers
		  https://arxiv.org/pdf/1902.01030.pdf
		  
		  a-3 Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction
		  https://www.aclweb.org/anthology/N18-1080.pdf
		  
		  分析：将实体抽取和关系抽取作为串联任务，先抽取实体，再抽取关系，建模相对更简单，易于实现。但当作两个独立的任务会存在一些问题。
		  一，误差积累：关系抽取任务的结果严重依赖于实体抽取的结果；
		  二，关系重叠：对于一对多问题，串联模型无法提供较好的解决方案；
		  三，交互缺失：忽略了两个子任务之间的内在联系和依赖关系。

		- b. 联合抽取Joint Model

		  联合模型，即将两个子模型统一建模，从而进一步利用两个任务之间的潜在信息，以缓解错误积累的问题。联合抽取的难点在于如何加强实体模型和关系模型之间的交互，比如实体模型和关系模型的输出之间存在着一定的约束，在建模的时候考虑到此类约束将有助于联合模型的性能。

			- 共享参数

			  通过共享参数（共享输入特征或者内部隐层状态）实现联合，这种方法对于子模型没有限制，但由于使用独立的解码方法，导致实体模型和关系模型之间的交互不强。
			    
			  b-1 依存结构树: End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures
			  https://www.aclweb.org/anthology/P16-1105.pdf
			  https://github.com/mkacan/entity-relation-extraction
			  
			  b-2 指针网络: Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees
			  https://pdfs.semanticscholar.org/bbbd/45338fbd85b0bacf23918bb77107f4cfb69e.pdf?_ga=2.119149259.311990779.1584453795-1756505226.1584453795
			  https://github.com/Luka0612/JEAR
			  
			  b-3_1 Copy机制+seq2seq: Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism
			  https://www.aclweb.org/anthology/P18-1047.pdf
			  https://github.com/xiangrongzeng/copy_re
			  b-3_2 CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning
			  https://arxiv.org/abs/1911.10438
			  https://github.com/WindChimeRan/CopyMTL
			  
			  b-4 多头选择机制+sigmoid: Joint entity recognition and relation extraction as a multi-head selection problem
			  https://arxiv.org/pdf/1804.07847.pdf
			  https://github.com/bekou/multihead_joint_entity_relation_extraction
			  
			  b-5 SPO问题+指针网络: Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy
			  https://yubowen-ph.github.io/files/2020_ECAI_ETL/ETL.pdf
			  https://github.com/yubowen-ph/JointER
			  
			  b-6 多轮对话+强化学习: Entity-Relation Extraction as Multi-Turn Question Answering
			  https://arxiv.org/pdf/1905.05529.pdf
			  https://zhuanlan.zhihu.com/p/65870466
			  
			  b-7 输入端的片段排列: Span-Level Model for Relation Extraction
			  https://www.aclweb.org/anthology/P19-1525.pdf
			  
			  b-8 输出端的片段排列: SpERT：Span-based Joint Entity and Relation Extraction with Transformer Pre-training
			  https://arxiv.org/pdf/1909.07755.pdf

			- 联合解码

			  复杂的联合解码方法，可以加强实体模型和关系模型的交互，如整数线性规划等。
			  
			  b-9 Joint extraction of entities and relations based on a novel tagging scheme
			  https://arxiv.org/pdf/1706.05075.pdf
			  https://github.com/zsctju/triplets-extraction
			  https://github.com/gswycf/Joint-Extraction-of-Entities-and-Relations-Based-on-a-Novel-Tagging-Scheme
			  
			  b-10 Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling
			  https://www.aaai.org/ojs/index.php/AAAI/article/view/4591
			  
			  b-11 Relation Extraction Baseline System—InfoExtractor 2.0
			  https://github.com/PaddlePaddle/Research/tree/master/KG/DuIE_Baseline
			  
			  各方法的详细介绍请阅读论文或看下面的链接。
			  详见https://zhuanlan.zhihu.com/p/77868938

	- 3. 基于深度学习半监督方法

		- a. 远程监督

		  定义：假设某对实体含有某种关系，那么只要含有这对实体的句子都含有这种关系。
		  优点：可获取大量数据，无需人工标注。
		  缺点：引入了大量的噪声。
		  
		  为了缓解噪声问题，可采取多示例学习、强化学习和与训练机制。
		  详见| https://zhuanlan.zhihu.com/p/77868938

		- b. Bootstrapping自扩展方法

		  比较常见的方法有DIPRE和Snowball，相比DIPRE，Snowball通常会对获得的模板样式进行置信度计算，一定程度上可以保证抽取结果的质量。
		  
		  定义：使用少量的样本去训练一个模型，然后利用模型去抽取更多的实例，再通过新数据做迭代训练。
		  
		  优点：所需数据少，构建成本低，适合大规模的关系任务并且具备发现新关系的能力。
		  缺点：对初始样本比较敏感，存在语义漂移，结果准确率低的情况。

	- 4. 无监督方法

	  利用语料中存在的大量冗余信息做聚类，在聚类结果的基础上给定关系，但由于聚类方法本身就存在难以描述关系和低频实例召回率低的问题，因此无监督学习一般难以得到很好的抽取效果。

- 属性抽取

  由于可以把实体的属性看作实体与属性值之间的一种名词性关系，因此属性抽取任务可以转化为关系抽取任务。

	- 转化为 关系抽取任务

- 三元组抽取

  三元组，即（S, P, O），S是头实体，O是尾实体，P是两个实体之间的关系。

	- 1. 基于DGCNN和概率图的轻量级信息抽取模型

	  优势：抽取结构是苏神自己设计的CNN+Attention，足够快速。
	  https://kexue.fm/archives/6671

	- 2. 基于Bert的三元组抽取

	  https://kexue.fm/archives/7161
	  https://github.com/bojone/bert_in_keras
	  https://github.com/bojone/bert4keras/blob/master/examples/task_relation_extraction.py

- 事件抽取

  事件的发生通常包括时间、地点、参与者等属性。事件是特定时间点或时间段、特定领域范围内，由一个或多个角色参与的一个或多个动作组成的事情或状态的改变。目前已存在的知识资源（如Wiki等）所描述实体及实体间的关联关系大多是静态的，事件能描述粒度更大的、动态的、结构化的知识，是现有知识资源的重要补充。
  
  事件抽取则是从自然语言文本中抽取出用户感兴趣的事件信息，并以结构化的形式展现出来。
  
  详见|事件抽取论文和方案
  https://zhuanlan.zhihu.com/p/136433610
  https://mp.weixin.qq.com/s/CRm5ky3J-eNim90oArD6Tg

	- 子任务

		- a. 事件触发词识别

		  即识别事件类型，如‘出生’、‘离职’等

		- b. 事件元素抽取与角色分类

		  事件元素的角色通常由两部分组成，事件参与者和时间属性，事件参与者是事件的必要部分，通常是命名实体的人名和组织机构名，事件属性包括通用事件属性和事件相关属性

		- d. 事件属性标注、事件共指消解等
		- c. 事件整体特性

		  如极性（正面/负面）、语态（确定/未知）、泛型（具体/普遍）、时态（过去/现在/将来/未知）

	- 方法

		- 1. 基于模板匹配

		  a. 基于人工标注语料
		  b. 基于弱监督
		  人工标注费时费力，且存在一致性问题，而弱监督方法无需对语料完全标注，只需人工对语料进行一定的预分类或者制定种子模板，由机器根据预分类语料或种子模板自动进行模式学习。
		  优势：在特定领域中性能较好，知识表示简洁，便于理解和后续应用。
		  劣势：对于语言、领域和文档形式都有不同程度的依赖，覆盖度和可移植性较差。

		- 2. 基于统计-传统机器学习

		  主要方法为将事件类别及事件元素的识别转换为分类问题。重点在于分类器和特征的选择，常用分类算法有SVM、ME等。
		  
		  优势：与领域无关，移植性好。
		  劣势：需要大规模已标注的标准语料，否则会有严重的数据稀疏。

		- 3. 基于统计-深度学习

		  类比于传统机器学习，主要方式还是将事件抽取的各步骤转换为分类问题，不过是将分类器换成了深度学习分类算法而已。另外，也有人将事件抽取转换为序列标注和MRC问题。



资料（模型过于繁多）：
https://www.cnblogs.com/sandwichnlp/p/12020066.html
https://www.cnblogs.com/sandwichnlp/p/12049829.html
http://shomy.top/2018/02/28/relation-extraction/
https://github.com/roomylee/awesome-relation-extraction
https://zhuanlan.zhihu.com/p/91762831
https://zhuanlan.zhihu.com/p/142615620
http://www.shuang0420.com/2018/09/15/知识抽取-实体及关系抽取/
http://www.shuang0420.com/2018/10/15/知识抽取-事件抽取/
https://github.com/smilelight/lightKG
https://github.com/loujie0822/DeepIE
